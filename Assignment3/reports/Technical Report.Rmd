---
title: 'Technical Report: Finding Fast Growing Firms'
author: "Shahana Ayobi"
date: '2023-02-26'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

```{r include=FALSE}
rm(list=ls())
library(glmnet)
library(margins)
library(skimr)
library(cowplot)
library(gmodels) 
library(modelsummary)
library(tidyverse)
library(viridis)
library(rattle)
library(caret)
library(pROC)
library(ranger)
library(rpart)
library(rpart.plot)
library(scales)
library(kableExtra)
library(Hmisc)
```

# Introduction
The purpose of this project is  to build a model that can predict the probability of fast growing companies vs non-fast ones. To classify those companies in the mentioned categories, a loss function is required that will quantify the the results of the modeling decisions. For this purpose, a threshold of 25% or more  of Compound Annual Growth Rate (CAGR) in sales is chosen. Which then classifies the companies into two categories: fast-growth companies with CAGR of 25% or more growth and non-fast-growth companies otherwise. The Logit, Logit LASSO, and Random Forest models with 5-fold cross validation were used in the prediction analysis. To determine the best model,  RMSE, AUC, and average expected loss as defined by the loss function were considered. Several company features were used in these models, including balance sheet items, profit and loss statements, and management.

# Label and Featutre Engineering
The data set contains detailed company specifications from 2005 to 2016 and includes 287,829 observations and 48 variables. Data was prepared by Bisnode, but was obtained from the [OSF](https://osf.io/3qyut/) website. In order to find a model to predict the probability of fast growing companies, the CAGR treshold was classified for companies with 25% or more sales growth over a two-year period. Companies with a CAGR of 25% or higher are classified as fast-growing, while others are classified as slow-growing. Furthermore, the data is filtered into a panel data of these companies from 2012 to 2014. Then the data was filtered on the companies that had data for these two years and CAGR was calculated. The reason for selecting a two-year time span rather than a single year was to ensure consistent sales growth, as sales numbers can fluctuate year to year. Furthermore, the reason for not selecting a longer time frame than 2012-2014 was a limitation in prediction power, as with longer time frames, prediction exercise becomes increasingly difficult.
In addition, a dummy variable was created to distinguish between businesses that were still operating and those whose sales were either NA or greater than 0. Based on this criterion, we only kept the companies that were regarded as being alive. Additionally, the data was further restricted to only include small and medium sized businesses. This assumption was made based on sales of between 1000 and 10 million euros. Lastly, observations with a CAGR of less than 250 were used with data from 2012 to make predictions.
Looking at sales distribution, it is skewed with longer right tail, thus log variable was created to make the sales close to normal distribution. The industry categories were combined combined together to decrease the number of categories of of the variable, and several service sand manufacturing industries were grouped together. By deducting the founding year from the present year of observation, the age of the company was then determined.
For other variables with skewed distribution winsorization method was used to identify a threshold value for each variable and  then replace values of variable that lie outside the threshold with the threshold value and add flag variables. As a result of the distribution of the main financial variables, we created some new variables. Because different types of assets are expected to be positive, we added a flag asset to identify assets that are greater than zero. Furthermore, for less than negative values, we assigned zero to all intangible, current, and fixed assets. Furthermore, we added new columns for all profit and loss variables and scaled them by dividing the variables by sales, as well as new balance sheet ratio variables by dividing the variables by total assets which was created by adding together the intangible, current, and fixed assets. Furthermore, because these ratios vary depending on the nature of the firm, we winorized them and kept the ratios between -1 and 1. Furthermore, we identified counting variables that could not be less than zero and created a flag variable called flag error to identify such values. In addition, we created a balance sheet variable that totals all assets. We also added some variables in the square and quadratic terms to capture non-linearity.

```{r include=FALSE, message=FALSE}

path <- "/Users/shahanaayobi/Desktop/RWork/Data-Analysis-3/Assignment3/"
#location folders
data_in  <- paste0(path,"/data/raw/")
data_out <- paste0(path,"/data/clean/")
output <- paste0(path, "/output/")
data <- read_csv("cs_bisnode_panel1.csv")
```


```{r include=FALSE, message=FALSE, warning=FALSE}
# check for missing values and drop the ones with more than 200k missing observations, and filter for years 2012 to 2014
to_filter <- sapply(data, function(x) sum(is.na(x)))
sort(to_filter[to_filter > 0])
data <- data %>%
  select(-c(COGS, finished_prod, net_dom_sales, net_exp_sales, wages, D, exit_date, exit_year)) %>%
  filter(year >= 2012,
         year <= 2014)
```


```{r include=FALSE, message=FALSE, warning=FALSE}
# add all missing year and comp_id combinations -
# originally missing combinations will have NAs in all other columns
data <- data %>%
  complete(year, comp_id)
# generate status_alive; if sales larger than zero and not-NA, then firm is alive
data  <- data %>%
  mutate(status_alive = sales > 0 & !is.na(sales) %>%
           as.numeric(.))
# defaults in two years if there are sales in this year but no sales two years later
data <- data %>%
  group_by(comp_id) %>%
  mutate(default = ((status_alive == 1) & (lead(status_alive, 2) == 0)) %>%
           as.numeric(.)) %>%
  ungroup()

# Size and growth
summary(data$sales) # There will be NAs, we'll drop them soon

# create sales in million and log sales
data <- data %>%
  mutate(sales = ifelse(sales < 0, 1, sales),
         ln_sales = ifelse(sales > 0, log(sales), 0),
         sales_mil=sales/1000000,
         sales_mil_log = ifelse(sales > 0, log(sales_mil), 0))
data$sales_mil_log_sq <- (data$sales_mil_log)^2 
# Keep only firms with data for the 3 years
data <- data %>% group_by(comp_id) %>% filter(n() == 3)
# Change in sales
data <- data %>%
  group_by(comp_id) %>%
  mutate(d1_sales_mil_log = sales_mil_log - Hmisc::Lag(sales_mil_log, 1) ) %>%
  ungroup()


# replace w 0 for new firms + add dummy to capture it
data <- data %>%
  mutate(age = (year - founded_year) %>%
           ifelse(. < 0, 0, .),
         new = as.numeric(age <= 1) %>% #  (age could be 0,1 )
           ifelse(balsheet_notfullyear == 1, 1, .),
         d1_sales_mil_log = ifelse(new == 1, 0, d1_sales_mil_log),
         new = ifelse(is.na(d1_sales_mil_log), 1, new),
         d1_sales_mil_log = ifelse(is.na(d1_sales_mil_log), 0, d1_sales_mil_log))

```

```{r include=FALSE, message=FALSE, warning=FALSE}
data <- data %>%
  mutate(flag_low_d1_sales_mil_log = ifelse(d1_sales_mil_log < -1.5, 1, 0),
         flag_high_d1_sales_mil_log = ifelse(d1_sales_mil_log > 1.5, 1, 0),
         d1_sales_mil_log_mod = ifelse(d1_sales_mil_log < -1.5, -1.5,
                                       ifelse(d1_sales_mil_log > 1.5, 1.5, d1_sales_mil_log)),
         d1_sales_mil_log_mod_sq = d1_sales_mil_log_mod^2)
```

```{r include=FALSE, message=FALSE, warning=FALSE}
# Filter out non-alive firms
data <- data %>%
  filter(status_alive == 1) %>%
  # look at firms below 10m euro revenues and above 1000 euros
  filter(!(sales_mil > 10)) %>%
  filter(!(sales_mil < 0.001))

# CAGR sales change in the last 2 years
data <- data %>%
  group_by(comp_id) %>%
  mutate(cagr_sales = ((lead(sales_mil,2) / sales_mil)^(1/2)-1)*100)
data <- data %>%
  filter(year == 2012,
         cagr_sales != is.na(cagr_sales),
         cagr_sales <= 250)


ggplot(data=data, aes(x=cagr_sales)) +
  geom_histogram(aes(y=(..count..)/sum(..count..)), binwidth = 10, boundary=0,
                 color = "white", fill = "#440154", alpha = 0.8) +
  coord_cartesian(xlim = c(-100, 250)) +
  labs(x = "CAGR growth",y = "Percent")+
  theme_bw() 

# Create fast growth dummy
data <- data %>%
  group_by(comp_id) %>%
  mutate(fast_growth = (cagr_sales > 25) %>%
           as.numeric(.)) %>%
  ungroup()

# create age variable
describe(data$fast_growth)
data <- data %>%
  mutate(age = (year - founded_year))


# change some industry category codes
data <- data %>%
  mutate(ind2_cat = ind2 %>%
           ifelse(. > 56, 60, .)  %>%
           ifelse(. < 26, 20, .) %>%
           ifelse(. < 55 & . > 35, 40, .) %>%
           ifelse(. == 31, 30, .) %>%
           ifelse(is.na(.), 99, .)
           )

table(data$ind2_cat)

# Firm characteristics
data <- data %>%
  mutate(age2 = age^2,
         foreign_management = as.numeric(foreign >= 0.5),
         gender_m = factor(gender, levels = c("female", "male", "mix")),
         m_region_loc = factor(region_m, levels = c("Central", "East", "West")))

```

```{r echo=FALSE, message=FALSE, warning=FALSE, out.width='50%'}
ggplot(data=data, aes(x=sales_mil)) +
  geom_histogram(aes(y = (..count..)/sum(..count..)), binwidth = 0.1,
                 color = "white", fill = "#440154") +
  coord_cartesian(xlim = c(0, 5)) +
  labs(x = "sales in million",y = "Percent", title = "Distribution of Sales")+
  theme_bw() 
ggplot(data=data, aes(x=sales_mil_log)) +
  geom_histogram(aes(y = (..count..)/sum(..count..)), binwidth = 0.25,
                 color = "white", fill = "#440154") +
  labs(x = "log sales in million",y = "Percent", title = "Distribution of log Sales")+
  theme_bw()
```

As the above graph shows that the distribution of sales is skewed to the right and log of sales has a close to normal distribution. 

```{r include=FALSE, message=FALSE, warning=FALSE}
ggplot(data=data, aes(x=cagr_sales)) +
  geom_histogram(aes(y = (..count..)/sum(..count..)), binwidth = 10, boundary=0,
                 color = "white", fill = "#440154") +
  coord_cartesian(xlim = c(-100, 200)) +
  labs(x = "CAGR growth",y = "Percent", title = "Distribution of CAGR growth")+
  theme_bw() 
```


```{r echo=FALSE, message=FALSE, warning=FALSE, out.width='50%'}
ggplot( data = data, aes( x = curr_assets ) ) +
  geom_histogram( color = "white", fill = "#440154") +
  theme(plot.title = element_text( size = 12L, face = "bold", hjust = 0.5 ) ) +
  scale_x_continuous(limits = c(-1, 1000000)) +
  scale_y_continuous(limits = c(0, 2800)) +
  labs( x='', y="Count", title= 'Current assets') +
  theme_bw()
ggplot( data = data, aes( x = curr_liab ) ) +
  geom_histogram( color = "white", fill = "#440154") +
  theme(plot.title = element_text( size = 12L, face = "bold", hjust = 0.5 ) ) +
  scale_x_continuous(limits = c(-1, 1000000)) +
  scale_y_continuous(limits = c(0, 2800)) +
  labs( x='', y="Count", title= 'Current Liabilities') +
  theme_bw()
ggplot( data = data, aes( x = inventories ) ) +
  geom_histogram( color = "white", fill = "#440154") +
  theme(plot.title = element_text( size = 12L, face = "bold", hjust = 0.5 ) ) +
  scale_x_continuous(limits = c(0, 100000)) +
  scale_y_continuous(limits = c(0, 2000)) +
  labs( x='', y="Count", title= 'Inventories') +
  theme_bw()
ggplot( data = data, aes( x = extra_inc ) ) +
  geom_histogram( color = "white", fill = "#440154") +
  theme(plot.title = element_text( size = 12L, face = "bold", hjust = 0.5 ) ) +
  scale_x_continuous(limits = c(-1, 50000)) +
  scale_y_continuous(limits = c(0, 200)) +
  labs( x='', y="", title= 'Extra Income') +
  theme_bw()
```


```{r include=FALSE, message=FALSE, warning=FALSE}
###########################################################
# look at more financial variables, create ratios
###########################################################

# assets can't be negative. Change them to 0 and add a flag.
data <-data  %>%
  mutate(flag_asset_problem=ifelse(intang_assets<0 | curr_assets<0 | fixed_assets<0,1,0  ))
table(data$flag_asset_problem)

data <- data %>%
  mutate(intang_assets = ifelse(intang_assets < 0, 0, intang_assets),
         curr_assets = ifelse(curr_assets < 0, 0, curr_assets),
         fixed_assets = ifelse(fixed_assets < 0, 0, fixed_assets))

# generate total assets
data <- data %>%
  mutate(total_assets_bs = intang_assets + curr_assets + fixed_assets)
summary(data$total_assets_bs)


pl_names <- c("extra_exp","extra_inc",  "extra_profit_loss", "inc_bef_tax" ,"inventories",
              "material_exp", "profit_loss_year", "personnel_exp")
bs_names <- c("intang_assets", "curr_liab", "fixed_assets", "liq_assets", "curr_assets",
              "share_eq", "subscribed_cap", "tang_assets" )

# divide all pl_names elements by sales and create new column for it
data <- data %>%
  mutate_at(all_of(pl_names), funs("pl"=./sales))

# divide all bs_names elements by total_assets_bs and create new column for it
data <- data %>% mutate_at(all_of(bs_names), funs("bs"=ifelse(total_assets_bs == 0, 0, ./total_assets_bs)))



########################################################################
# creating flags, and winsorizing tails
########################################################################

# Variables that represent accounting items that cannot be negative (e.g. materials)
zero <-  c("extra_exp_pl", "extra_inc_pl", "inventories_pl", "material_exp_pl", "personnel_exp_pl",
           "curr_liab_bs", "fixed_assets_bs", "liq_assets_bs", "curr_assets_bs", "subscribed_cap_bs",
           "intang_assets_bs")

data <- data %>%
  mutate_at(vars(zero), funs("flag_high"= as.numeric(.> 1))) %>%
  mutate_at(vars(zero), funs(ifelse(.> 1, 1, .))) %>%
  mutate_at(vars(zero), funs("flag_error"= as.numeric(.< 0))) %>%
  mutate_at(vars(zero), funs(ifelse(.< 0, 0, .)))


# for vars that could be any, but are mostly between -1 and 1
any <-  c("extra_profit_loss_pl", "inc_bef_tax_pl", "profit_loss_year_pl", "share_eq_bs")

data <- data %>%
  mutate_at(all_of(any), funs("flag_low"= as.numeric(.< -1))) %>%
  mutate_at(all_of(any), funs(ifelse(.< -1, -1, .))) %>%
  mutate_at(all_of(any), funs("flag_high"= as.numeric(.> 1))) %>%
  mutate_at(all_of(any), funs(ifelse(.> 1, 1, .))) %>%
  mutate_at(all_of(any), funs("flag_zero"= as.numeric(.== 0))) %>%
  mutate_at(all_of(any), funs("quad"= .^2))


# dropping flags with no variation
variances<- data %>%
  select(contains("flag")) %>%
  apply(2, var, na.rm = TRUE) == 0

data <- data %>%
  select(-one_of(names(variances)[variances]))

########################################################################
# additional
# including some imputation
########################################################################

# CEO age
data <- data %>%
  mutate(ceo_age = year-birth_year,
         flag_low_ceo_age = as.numeric(ceo_age < 25 & !is.na(ceo_age)),
         flag_high_ceo_age = as.numeric(ceo_age > 75 & !is.na(ceo_age)),
         flag_miss_ceo_age = as.numeric(is.na(ceo_age)))

data <- data %>%
  mutate(ceo_age = ifelse(ceo_age < 25, 25, ceo_age) %>%
           ifelse(. > 75, 75, .) %>%
           ifelse(is.na(.), mean(., na.rm = TRUE), .),
         ceo_young = as.numeric(ceo_age < 40))

# number emp, very noisy measure
data <- data %>%
  mutate(labor_avg_mod = ifelse(is.na(labor_avg), mean(labor_avg, na.rm = TRUE), labor_avg),
         flag_miss_labor_avg = as.numeric(is.na(labor_avg))) %>% mutate(sales_mil_log_sq=as.numeric(sales_mil_log)^2)

summary(data$labor_avg)
summary(data$labor_avg_mod)

data <- data %>%
  select(-labor_avg)

# create factors
data <- data %>%
  mutate(urban_m = factor(urban_m, levels = c(1,2,3)),
         ind2_cat = factor(ind2_cat, levels = sort(unique(data$ind2_cat))))

data <- data %>%
  mutate(fast_growth_f = factor(fast_growth, levels = c(0,1)) %>%
           recode(., `0` = 'no_fast_growth', `1` = "fast_growth"))

# no more imputation, drop obs if key vars missing
data <- data %>%
  filter(!is.na(liq_assets_bs),!is.na(foreign), !is.na(ind))
# drop missing
data <- data %>%
  filter(!is.na(age),!is.na(foreign), !is.na(material_exp_pl), !is.na(m_region_loc))
Hmisc::describe(data$age)
# drop unused factor levels
data <- data %>%
  mutate_at(vars(colnames(data)[sapply(data, is.factor)]), funs(fct_drop))

income_before <- ggplot(data = data, aes(x=inc_bef_tax_pl, y=as.numeric(fast_growth))) +
  geom_point(size=2,  shape=20, stroke=2, fill="blue", color="blue") +
  geom_smooth(method="loess", se=F, colour="black", size=1.5, span=0.9) +
  labs(x = "Income before taxes",y = "Fast Growth distribution") +
  theme_bw() +
  scale_x_continuous(limits = c(-1.5,1.5), breaks = seq(-1.5,1.5, 0.5))

income_before

```

```{r include=FALSE, message=FALSE, warning=FALSE}
# Define variable sets ----------------------------------------------
# (making sure we use ind2_cat, which is a factor)
rawvars <-  c("curr_assets", "curr_liab", "extra_exp", "extra_inc", "extra_profit_loss", "fixed_assets",
              "inc_bef_tax", "intang_assets", "inventories", "liq_assets", "material_exp", "personnel_exp",
              "profit_loss_year", "sales", "share_eq", "subscribed_cap")
qualityvars <- c("balsheet_flag", "balsheet_length", "balsheet_notfullyear")
engvar <- c("total_assets_bs", "fixed_assets_bs", "liq_assets_bs", "curr_assets_bs",
            "share_eq_bs", "subscribed_cap_bs", "intang_assets_bs", "extra_exp_pl",
            "extra_inc_pl", "extra_profit_loss_pl", "inc_bef_tax_pl", "inventories_pl",
            "material_exp_pl", "profit_loss_year_pl", "personnel_exp_pl")
engvar2 <- c("extra_profit_loss_pl_quad", "inc_bef_tax_pl_quad",
             "profit_loss_year_pl_quad", "share_eq_bs_quad")
engvar3 <- c(grep("*flag_low$", names(data), value = TRUE),
             grep("*flag_high$", names(data), value = TRUE),
             grep("*flag_error$", names(data), value = TRUE),
             grep("*flag_zero$", names(data), value = TRUE))
d1 <-  c("d1_sales_mil_log_mod", "d1_sales_mil_log_mod_sq",
         "flag_low_d1_sales_mil_log", "flag_high_d1_sales_mil_log")
hr <- c("female", "ceo_age", "flag_high_ceo_age", "flag_low_ceo_age",
        "flag_miss_ceo_age", "ceo_count", "labor_avg_mod",
        "flag_miss_labor_avg", "foreign_management")
firm <- c("age", "age2", "new", "ind2_cat", "m_region_loc", "urban_m")
# interactions for logit, LASSO
interactions1 <- c("ind2_cat*age", "ind2_cat*age2",
                   "ind2_cat*d1_sales_mil_log_mod", "ind2_cat*sales_mil_log",
                   "ind2_cat*ceo_age", "ind2_cat*foreign_management",
                   "ind2_cat*female",   "ind2_cat*urban_m", "ind2_cat*labor_avg_mod")
interactions2 <- c("sales_mil_log*age", "sales_mil_log*female",
                   "sales_mil_log*profit_loss_year_pl", "sales_mil_log*foreign_management")
X1 <- c("sales_mil_log", "sales_mil_log_sq", "d1_sales_mil_log_mod", "profit_loss_year_pl", "ind2_cat")
X2 <- c("sales_mil_log", "sales_mil_log_sq", "d1_sales_mil_log_mod", "profit_loss_year_pl", "fixed_assets_bs","share_eq_bs","curr_liab_bs ",   "curr_liab_bs_flag_high ", "curr_liab_bs_flag_error",  "age","foreign_management" , "ind2_cat")
X3 <- c("sales_mil_log", "sales_mil_log_sq", firm, engvar,d1)
X4 <- c("sales_mil_log", "sales_mil_log_sq", firm, engvar, engvar2, engvar3, d1, hr, qualityvars)
X5 <- c("sales_mil_log", "sales_mil_log_sq", firm, engvar, engvar2, engvar3, d1, hr, qualityvars, interactions1, interactions2)
# for LASSO

logitvars <- c("sales_mil_log", "sales_mil_log_sq", engvar, engvar2, engvar3, d1, hr, firm, qualityvars, interactions1, interactions2)
# for RF (no interactions, no modified features)
rfvars  <-  c("sales_mil", "d1_sales_mil_log", rawvars, hr, firm, qualityvars)
# Check simplest model X1
ols_modelx1 <- lm(formula(paste0("fast_growth ~", paste0(X1, collapse = " + "))),
                  data = data)
summary(ols_modelx1)
glm_modelx1 <- glm(formula(paste0("fast_growth ~", paste0(X1, collapse = " + "))),
                   data = data, family = "binomial")
summary(glm_modelx1)
# Check model X2
glm_modelx2 <- glm(formula(paste0("fast_growth ~", paste0(X2, collapse = " + "))),
                   data = data, family = "binomial")
summary(glm_modelx2)

#calculate average marginal effects (dy/dx) for logit
mx2 <- margins(glm_modelx2)
sum_table <- summary(glm_modelx2) %>%
  coef() %>%
  as.data.frame() %>%
  select(Estimate) %>%
  mutate(factor = row.names(.)) %>%
  merge(summary(mx2)[,c("factor","AME")])
kable(x = sum_table, format = "latex", digits = 3,
      col.names = c("Variable", "Coefficient", "dx/dy"),
      caption = "Average Marginal Effects (dy/dx) for Logit Model")
# baseline model is X4 (all vars, but no interactions) -------------------------------------------------------
data <- data %>%
  mutate(flag_low_d1_sales_mil_log = ifelse(d1_sales_mil_log < -1.5, 1, 0),
         flag_high_d1_sales_mil_log = ifelse(d1_sales_mil_log > 1.5, 1, 0),
         d1_sales_mil_log_mod = ifelse(d1_sales_mil_log < -1.5, -1.5,
                                       ifelse(d1_sales_mil_log > 1.5, 1.5, d1_sales_mil_log)),
         d1_sales_mil_log_mod_sq = d1_sales_mil_log_mod^2)

ols_model <- lm(formula(paste0("fast_growth ~", paste0(X4, collapse = " + "))),
                data = data)
summary(ols_model)
glm_model <- glm(formula(paste0("fast_growth ~", paste0(X4, collapse = " + "))),
                 data = data, family = "binomial")
summary(glm_model)
#calculate average marginal effects (dy/dx) for logit
# vce="none" makes it run much faster, here we do not need variances
m <- margins(glm_model, vce = "none")
sum_table2 <- summary(glm_model) %>%
  coef() %>%
  as.data.frame() %>%
  select(Estimate, `Std. Error`) %>%
  mutate(factor = row.names(.)) %>%
  merge(summary(m)[,c("factor","AME")])
knitr::kable(sum_table2, digits = 3,
      col.names = c("Variable", "Coefficient", "SE", "dx/dy"),
      caption = "Average Marginal Effects (dy/dx) for Logit Model")

```




```{r echo= FALSE, message=FALSE, warning=FALSE}
summ<- datasummary((`Growth` = as.factor(fast_growth_f)) ~ N + Percent(), data = data, title = "Firm Growth Summary") %>% kable_minimal(full_width = F, html_font = "Cambria") %>% kable_styling(latex_options = c("HOLD_position", "resizebox=2.5\\textwidth"), font_size = 12, full_width = T) 
summ
```

```{r echo=FALSE}
model_variables <- data.frame ( "Models" = c("M1 : Log sales + Log sales sq + Change in sales + Profit and loss + Industry", "M2 :M1 + Fixed assets + Equity + Current liabilities + Age + Foreign management", "M3 : Log sales + Log sales sq + Firm + Engine variables 1 + D1", "M4 : M3 + Engine variables 2 + Engine variables 3 + HR", "M5 : M4 + Interactions 1 and 2", "LASSO logit : same as M5", "Random Forest : Log sales + Log sales sq, Raw variables, human resource"))
model_table_viewxx <- model_variables %>%
  kbl(caption = "Firm Exit Predictor Variables") %>%
  kable_minimal(full_width = F, html_font = "Cambria") %>% kable_styling(latex_options = c("HOLD_position", "resizebox=2.5\\textwidth"), font_size = 12, full_width = T) 

model_table_viewxx
```
# Modeling
The original cleaned data is split into two random parts by 20% to 80% ratio in order to avoid over-fitting. The Holdout set includes 20% and the rest 80% is work data set. Then, the work data set is split into train and test data sets and  5-fold cross validation is run on the train datas et. Then the best model is chosen based on the lowest average of 5 CV RMSE result. 

# Probablity Logit Model
The logit probability prediction was performed first by selecting the best logit model through cross-validation, and evaluating the model using the holdout set. To find a better model to use for further analysis, five different logit models were considered, ranked from simplest to most complex. The M1 logit model includes variables based on domain knowledge, and we included variables that we thought were important. The results of RMSE and AUC for the five logit models show that the RMSE results have very small differences. Thus, the Model X4 has the lowest RMSE of 0.3965 and the highest AUC of 0.7077. Thus model 4 is chosen for further analysis.
```{r include=FALSE, message=FALSE, warning=FALSE}
set.seed(123456)
train_indices <- as.integer(createDataPartition(data$fast_growth, p = 0.8, list = FALSE))
data_train <- data[train_indices, ]
data_holdout <- data[-train_indices, ]
dim(data_train)
dim(data_holdout)
Hmisc::describe(data$fast_growth_f)
Hmisc::describe(data_train$fast_growth_f)
Hmisc::describe(data_holdout
                $fast_growth_f)


# helper functions for classification code: ch17-predicting-firm-exit

twoClassSummaryExtended <- function (data, lev = NULL, model = NULL)
{
  lvls <- levels(data$obs)
  rmse <- sqrt(mean((data[, lvls[1]] - ifelse(data$obs == lev[2], 0, 1))^2))
  c(defaultSummary(data, lev, model), "RMSE" = rmse)
}
#######################################################x
# PART I PREDICT PROBABILITIES
# Predict logit models ----------------------------------------------
#######################################################x
# 5 fold cross-validation
train_control <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE,
  summaryFunction = twoClassSummaryExtended,
  savePredictions = TRUE
)
# Train Logit Models ----------------------------------------------
logit_model_vars <- list("X1" = X1, "X2" = X2, "X3" = X3, "X4" = X4, "X5" = X5)
CV_RMSE_folds <- list()
logit_models <- list()
for (model_name in names(logit_model_vars)) {
  
  features <- logit_model_vars[[model_name]]
  
  set.seed(123456)
  glm_model <- train(
    formula(paste0("fast_growth_f ~", paste0(features, collapse = " + "))),
    method = "glm",
    data = data_train,
    family = binomial,
    trControl = train_control
  )
  
  logit_models[[model_name]] <- glm_model
  # Calculate RMSE on test for each fold
  CV_RMSE_folds[[model_name]] <- glm_model$resample[,c("Resample", "RMSE")]
  
}
# Logit lasso -----------------------------------------------------------
lambda <- 10^seq(-1, -4, length = 10)
grid <- expand.grid("alpha" = 1, lambda = lambda)
set.seed(123456)
system.time({
  logit_lasso_model <- train(
    formula(paste0("fast_growth_f ~", paste0(logitvars, collapse = " + "))),
    data = data_train,
    method = "glmnet",
    preProcess = c("center", "scale"),
    family = "binomial",
    trControl = train_control,
    tuneGrid = grid,
    na.action=na.exclude
  )
})
tuned_logit_lasso_model <- logit_lasso_model$finalModel
best_lambda <- logit_lasso_model$bestTune$lambda
logit_models[["LASSO"]] <- logit_lasso_model
lasso_coeffs <- as.matrix(coef(tuned_logit_lasso_model, best_lambda))
write.csv(lasso_coeffs, paste0(output, "lasso_logit_coeffs.csv"))
CV_RMSE_folds[["LASSO"]] <- logit_lasso_model$resample[,c("Resample", "RMSE")]
```


```{r include=FALSE, message=FALSE, warning=FALSE}
#############################################x
# PART I
# No loss fn
########################################
# Draw ROC Curve and calculate AUC for each folds --------------------------------
CV_AUC_folds <- list()
for (model_name in names(logit_models)) {
  
  auc <- list()
  model <- logit_models[[model_name]]
  for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
    cv_fold <-
      model$pred %>%
      filter(Resample == fold)
    
    roc_obj <- roc(cv_fold$obs, cv_fold$fast_growth)
    auc[[fold]] <- as.numeric(roc_obj$auc)
  }
  
  CV_AUC_folds[[model_name]] <- data.frame("Resample" = names(auc),
                                           "AUC" = unlist(auc))
}
# For each model: average RMSE and average AUC for models ----------------------------------
CV_RMSE <- list()
CV_AUC <- list()
for (model_name in names(logit_models)) {
  CV_RMSE[[model_name]] <- mean(CV_RMSE_folds[[model_name]]$RMSE)
  CV_AUC[[model_name]] <- mean(CV_AUC_folds[[model_name]]$AUC)
}
# We have 6 models, (5 logit and the logit lasso). For each we have a 5-CV RMSE and AUC.
# We pick our preferred model based on that. -----------------------------------------------
nvars <- lapply(logit_models, FUN = function(x) length(x$coefnames))
nvars[["LASSO"]] <- sum(lasso_coeffs != 0)
logit_summary1 <- data.frame("Number of predictors" = unlist(nvars),
                             "CV RMSE" = unlist(CV_RMSE),
                             "CV AUC" = unlist(CV_AUC))
kable(x = logit_summary1, format = "latex", booktabs=TRUE,  digits = 3, row.names = TRUE,
      linesep = "", col.names = c("Number of predictors","CV RMSE","CV AUC")) %>%
  cat(.,file= paste0(output, "logit_summary1.tex"))
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
logit_summary1 %>% 
  slice(1:5) %>% 
  kbl() %>% 
  kable_classic(full_width = T, html_font = "Cambria") %>% kable_styling(latex_options = c("HOLD_position", "resizebox=2.5\\textwidth"), font_size = 12, full_width = T) 
```


# Logit LASSO
LASSO is an algorithm that fits a model by shrinking coefficients, some of which are reduced to zero by the addition of a penalty term. LASSO for logit is run in this set of models and all of the variables and interactions are included in the Logit Model 5. As a result, LASSO generates a model that includes the majority of the variables but excludes some. Based on the results, it is concluded that LASSO performs well in terms of RMSE with 0.3962, whereas the fourth simple logit model performs better in terms of AUC.

# Random Forest
Because Random Forest can assign functional forms and interactions, the variables in the random forest do not have any patterns. In each split, the random forest tuning parameter was set to 5, 6, or 7. the result shows that Random Forest outperforms other models like LASSO and probability logit with RMSE of 0.3946, and the AUC value of 0.7108 . As a result, the Random Forest model with the lowest RMSE and highest AUC is the best performer. As a result, an ROC curve is drawn using our holdout set.

```{r message=FALSE, warning=FALSE, include=FALSE}
# 5 fold cross-validation
train_control <- trainControl(
  method = "cv",
  n = 5,
  classProbs = TRUE, # same as probability = TRUE in ranger
  summaryFunction = twoClassSummaryExtended,
  savePredictions = TRUE
)
train_control$verboseIter <- TRUE
tune_grid <- expand.grid(
  .mtry = c(5, 6, 7),
  .splitrule = "gini",
  .min.node.size = c(10, 15)
)
# build rf model
set.seed(20230220)
rf_model_p <- train(
  formula(paste0("fast_growth_f ~ ", paste0(rfvars , collapse = " + "))),
  method = "ranger",
  data = data_train,
  tuneGrid = tune_grid,
  trControl = train_control,
)
best_mtry <- rf_model_p$bestTune$mtry
best_min_node_size <- rf_model_p$bestTune$min.node.size
# Get average (ie over the folds) RMSE and AUC ------------------------------------
CV_RMSE_folds[["rf_p"]] <- rf_model_p$resample[,c("Resample", "RMSE")]
auc <- list()
for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
  cv_fold <-
    rf_model_p$pred %>%
    filter(Resample == fold)
  
  roc_obj <- roc(cv_fold$obs, cv_fold$fast_growth)
  auc[[fold]] <- as.numeric(roc_obj$auc)
}
CV_AUC_folds[["rf_p"]] <- data.frame("Resample" = names(auc),
                                     "AUC" = unlist(auc))
CV_RMSE[["Random_forest"]] <- mean(CV_RMSE_folds[["rf_p"]]$RMSE)
CV_AUC[["Random_forest"]] <- mean(CV_AUC_folds[["rf_p"]]$AUC)
rf_summary <- data.frame("CV RMSE" = unlist(CV_RMSE),
                         "CV AUC" = unlist(CV_AUC))
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
rf_summary %>% 
  slice(c(4,7)) %>% 
  kbl() %>% 
  kable_classic(full_width = T, html_font = "Cambria") %>% kable_styling(latex_options = c("HOLD_position", "resizebox=2.5\\textwidth"), font_size = 12, full_width = T) 
```

The ROC curve below illustrates the trade-off that occurs when various categorization criteria are applied to the probability predictions from an estimated model. Also, the ROC curve displays the proportion of true positives among all y = 1 data as well as the false positive rate among all y = 0 observations. Its AUC is 0.7108 based on the output from the best Random Forest model. A lower threshold, suggests both more true positives and more false positives. A higher threshold indicates fewer false positives or real positives. As a result, by looking at the curve below, we must determine a threshold, for which we must design the loss function.

```{r echo=F, message=FALSE, warning=FALSE}
best_no_loss <- rf_model_p
predicted_probabilities_holdout <- predict(best_no_loss, newdata = data_holdout, type = "prob")
data_holdout[,"best_no_loss_pred"] <- predicted_probabilities_holdout[,"fast_growth"]
# discrete ROC (with thresholds in steps) on holdout -------------------------------------------------
thresholds <- seq(0.05, 0.75, by = 0.025)
cm <- list()
true_positive_rates <- c()
false_positive_rates <- c()
for (thr in thresholds) {
  holdout_prediction <- ifelse(data_holdout[,"best_no_loss_pred"] < thr, "no_fast_growth", "fast_growth") %>%
    factor(levels = c("no_fast_growth", "fast_growth"))
  cm_thr <- confusionMatrix(holdout_prediction,data_holdout$fast_growth_f)$table
  cm[[as.character(thr)]] <- cm_thr
  true_positive_rates <- c(true_positive_rates, cm_thr["fast_growth", "fast_growth"] /
                             (cm_thr["fast_growth", "fast_growth"] + cm_thr["no_fast_growth", "fast_growth"]))
  false_positive_rates <- c(false_positive_rates, cm_thr["fast_growth", "no_fast_growth"] /
                              (cm_thr["fast_growth", "no_fast_growth"] + cm_thr["no_fast_growth", "no_fast_growth"]))
}
tpr_fpr_for_thresholds <- tibble(
  "threshold" = thresholds,
  "true_positive_rate" = true_positive_rates,
  "false_positive_rate" = false_positive_rates
)
ggplot(
  data = tpr_fpr_for_thresholds,
  aes(x = false_positive_rate, y = true_positive_rate, color = threshold)) +
  labs(x = "False positive rate (1 - Specificity)", y = "True positive rate (Sensitivity)") +
  geom_point(size=2, alpha=0.8) +
  scale_color_viridis(option = "D", direction = -1) +
  scale_x_continuous(expand = c(0.01,0.01), limit=c(0,1), breaks = seq(0,1,0.1)) +
  scale_y_continuous(expand = c(0.01,0.01), limit=c(0,1), breaks = seq(0,1,0.1)) +
  theme_bw() +
  theme(legend.position ="right") +
  theme(legend.title = element_text(size = 4), 
        legend.text = element_text(size = 4),
        legend.key.size = unit(.4, "cm")) 
# continuous ROC on holdout with best model (Logit 4) -------------------------------------------
roc_obj_holdout <- roc(data_holdout$fast_growth, data_holdout$best_no_loss_pred)
```


# Model Evaluation and Confusion Matrix

As a result, when compared to Logit LASSO, Logit Model 4, and Logit Model 1, Random Forest has the lowest expected loss and RMSE. However, the logit Model performs similarly. The expected loss from Model 4 is nearly identical to that of Random Forest, with only a 0.002 difference. The RMSE differs by 0.0019, which is quite negligible. Thus, choosing Model 4 makes more sense since it can be easily interpreted compared to Random Forest.
After creating confusion matrix for model 4, it is apparent that the accuracy of the model is 76% meaning it correctly predicted 76% of the firms. Model specificity is 87% which demonstrates that from not fast growing firms the model correctly estimated 87%. Eventually, model sensitivity is 38% meaning that model predicted the fast growing firms by 38%.
```{r include=FALSE, warning=FALSE, message=FALSE}
# Confusion table with different tresholds ----------------------------------------------------------
# fast_growth: the threshold 0.5 is used to convert probabilities to binary classes
class_prediction <- predict(best_no_loss, newdata = data_holdout)
summary(class_prediction)
# confusion matrix: summarize different type of errors and successfully predicted cases
# positive = "yes": explicitly specify the positive case
cm_object1 <- confusionMatrix(class_prediction, data_holdout$fast_growth_f, positive = "fast_growth")
cm1 <- cm_object1$table
cm1
# a sensible choice: mean of predicted probabilities
mean_predicted_fast_growth_prob <- mean(data_holdout$best_no_loss_pred)
mean_predicted_fast_growth_prob
holdout_prediction <-
  ifelse(data_holdout$best_no_loss_pred < mean_predicted_fast_growth_prob, "no_fast_growth", "fast_growth") %>%
  factor(levels = c("no_fast_growth", "fast_growth"))
cm_object2 <- confusionMatrix(holdout_prediction,data_holdout$fast_growth_f)
cm2 <- cm_object2$table
cm2
##############################################################
#                                                            #
#                           PART IIV                         #
#  ----- Probability prediction with a loss function ------  #
#                                                            #
##############################################################
# Introduce loss function
# relative cost of of a false negative classification (as compared with a false positive classification)
FP=1
FN=2
cost = FN/FP
# the prevalence, or the proportion of cases in the population (n.cases/(n.controls+n.cases))
prevelance = sum(data_train$fast_growth)/length(data_train$fast_growth)
#################################
#        Logit and LASOO        #
#################################
# Draw ROC Curve and find optimal threshold with loss function --------------------------
best_tresholds <- list()
expected_loss <- list()
logit_cv_rocs <- list()
logit_cv_threshold <- list()
logit_cv_expected_loss <- list()
for (model_name in names(logit_models)) {
  
  model <- logit_models[[model_name]]
  colname <- paste0(model_name,"_prediction")
  
  best_tresholds_cv <- list()
  expected_loss_cv <- list()
  
  for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
    cv_fold <-
      model$pred %>%
      filter(Resample == fold)
    
    roc_obj <- roc(cv_fold$obs, cv_fold$fast_growth)
    best_treshold <- coords(roc_obj, "best", ret="all", transpose = FALSE,
                            best.method="youden", best.weights=c(cost, prevelance))
    best_tresholds_cv[[fold]] <- best_treshold$threshold
    expected_loss_cv[[fold]] <- (best_treshold$fp*FP + best_treshold$fn*FN)/length(cv_fold$fast_growth)
  }
  
  # average
  best_tresholds[[model_name]] <- mean(unlist(best_tresholds_cv))
  expected_loss[[model_name]] <- mean(unlist(expected_loss_cv))
  
  # for fold #5
  logit_cv_rocs[[model_name]] <- roc_obj
  logit_cv_threshold[[model_name]] <- best_treshold
  logit_cv_expected_loss[[model_name]] <- expected_loss_cv[[fold]]
  
}
logit_summary2 <- data.frame("Avg of optimal thresholds" = unlist(best_tresholds),
                             "Threshold for Fold5" = sapply(logit_cv_threshold, function(x) {x$threshold}),
                             "Avg expected loss" = unlist(expected_loss),
                             "Expected loss for Fold5" = unlist(logit_cv_expected_loss))
#################################
#         Random forest         #
#################################
# Now use loss function and search for best thresholds and expected loss over folds -----
best_tresholds_cv <- list()
expected_loss_cv <- list()
for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
  cv_fold <-
    rf_model_p$pred %>%
    filter(mtry == best_mtry,
           min.node.size == best_min_node_size,
           Resample == fold)
  
  roc_obj <- roc(cv_fold$obs, cv_fold$fast_growth)
  best_treshold <- coords(roc_obj, "best", ret="all", transpose = FALSE,
                          best.method="youden", best.weights=c(cost, prevelance))
  best_tresholds_cv[[fold]] <- best_treshold$threshold
  expected_loss_cv[[fold]] <- (best_treshold$fp*FP + best_treshold$fn*FN)/length(cv_fold$fast_growth)
}
# average
best_tresholds[["rf_p"]] <- mean(unlist(best_tresholds_cv))
expected_loss[["rf_p"]] <- mean(unlist(expected_loss_cv))
# Save output --------------------------------------------------------
# Model selection is carried out on this CV RMSE
nvars[["rf_p"]] <- length(rfvars)
summary_results <- data.frame("Number of predictors" = unlist(nvars),
                              "CV RMSE" = unlist(CV_RMSE),
                              "CV AUC" = unlist(CV_AUC),
                              "CV threshold" = unlist(best_tresholds),
                              "CV expected Loss" = unlist(expected_loss))
model_names <- c("Logit X1", "Logit X4",
                 "Logit LASSO","RF probability")
summary_results <- summary_results %>%
  filter(rownames(.) %in% c("X1", "X4", "LASSO", "rf_p"))
rownames(summary_results) <- model_names
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
summary_results %>% 
  kbl %>% 
  kable_classic(full_width = T, html_font = "Cambria") %>%kable_styling(latex_options = c("HOLD_position", "resizebox=2.5\\textwidth"), full_width = T) 
```
```{r echo=FALSE, message=FALSE, warning=FALSE}
best_logit_with_loss <- logit_models[["X4"]]
best_logit_optimal_treshold <- best_tresholds[["X4"]]
logit_predicted_probabilities_holdout <- predict(best_logit_with_loss, newdata = data_holdout, type = "prob")
data_holdout[,"best_logit_with_loss_pred"] <- logit_predicted_probabilities_holdout[,"fast_growth"]
# ROC curve on holdout
roc_obj_holdout <- roc(data_holdout$fast_growth, data_holdout[, "best_logit_with_loss_pred", drop=TRUE])
# Get expected loss on holdout
holdout_treshold <- coords(roc_obj_holdout, x = best_logit_optimal_treshold, input= "threshold",
                           ret="all", transpose = FALSE)
expected_loss_holdout <- (holdout_treshold$fp*FP + holdout_treshold$fn*FN)/length(data_holdout$fast_growth)
# Confusion table on holdout with optimal threshold
holdout_prediction <-
  ifelse(data_holdout$best_logit_with_loss_pred < best_logit_optimal_treshold, "no_fast_growth", "fast_growth") %>%
  factor(levels = c("no_fast_growth", "fast_growth"))
cm_object3 <- confusionMatrix(holdout_prediction,data_holdout$fast_growth_f)
cm3 <- cm_object3$table
cm3 %>% 
  kbl() %>% 
  kable_classic(full_width = T, html_font = "Cambria") %>% kable_styling(latex_options = c("HOLD_position", "resizebox=2.5\\textwidth"), font_size = 12, full_width = T) 
```


$$accuracy = \frac{TP + TN}{N} = \frac{250+1928} {2872} = 76\%$$
$$sensitivity = \frac{TP}{TP + FN} = \frac{250} {250+ 408} = 38\%$$
$$specifcity = \frac{TN}{TN + FP} = \frac{1928} {1928 + 286} = 87\%$$



# Conclusion
The final model chosen for this case study was Model 4, which includes the variable of firm details as well as all engine variables such as firm financial information such as balance sheet and profit and loss, as well as HR variables. The The model's accuracy is 76%. The model correctly estimated 87% of firms that were not rapidly growing. It eventually predicted 38% of fast-growing firms. However, running these models over several time periods is encouraged, and it might be a good idea to evaluate many time periods, in order to verify external validity. It is also advised to run the model separately on small and medium-sized businesses that are focused on a certain industry. Perhaps this would produce findings that are more focused, enabling the investing companies to make informed decisions.

















