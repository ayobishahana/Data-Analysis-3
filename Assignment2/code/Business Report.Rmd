---
title: "Business Report: Building Price Prediction Models For Copenhagen Apartments"
author: "Shahana Ayobi"
date: '2023-02-12'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# Clearing the environment
rm(list=ls())
# Loading the Libraries
library(tidyverse)
library(caret)
library(modelsummary)
library(stargazer)
library(xtable)
library(rattle)
library(kableExtra)
library(data.table)
library(ggplot2)
library(GGally)
library(gridExtra)
library(knitr)
library(viridis)
library(directlabels)
library(Hmisc)
library(cowplot)
library(ranger)
library(glmnet)
library(grid)
library(skimr)
library(gbm)
library(fixest)
library(rpart)
library(rpart.plot)

path <- "/Users/shahanaayobi/Desktop/RWork/Data-Analysis-3/Assignment2/"
#location folders
data_in  <- paste0(path,"/data/raw/")
data_out <- paste0(path,"/data/clean/")
output <- paste0(path, "/output/")
df<- read.csv(paste0(data_out,"airbnb_cleaned.csv"), fileEncoding="UTF-8")
```



```{r message=FALSE, warning=FALSE, include=FALSE}
# Looking for interactions.
  # It is a function it takes 3 arguments: 1) Your dataframe,
  # 2) the factor variable (like room_type)
  # 3)the dummy variable you are interested in (like TV)
price_diff_by_variables2 <- function(df, factor_var, dummy_var, factor_lab, dummy_lab){
  
  # Process your data frame and make a new dataframe which contains the stats
  factor_var <- as.name(factor_var)
  dummy_var <- as.name(dummy_var)
  
  stats <- df %>%
    group_by(!!factor_var, !!dummy_var) %>%
    dplyr::summarize(
      Mean = mean(price_daily, na.rm=TRUE),se = sd(price_daily)/sqrt(n()))
  
  stats[,2] <- lapply(stats[,2], factor)
  
  ggplot(
  stats, 
  aes_string(colnames(stats)[1], colnames(stats)[3], fill = colnames(stats)[2])) +
  geom_bar(
    stat='identity', 
    position = position_dodge(width=0.9), 
    alpha=0.8) +
  geom_errorbar(
    aes(ymin=Mean-(1.96*se),ymax=Mean+(1.96*se)),
    position=position_dodge(width = 0.9), 
    width = 0.25) +
  scale_color_manual(
    name=dummy_lab,
    values=c("#000000", "#990033", "#006699", "#33CC00", "#996633")) +
  scale_fill_manual(
    name=dummy_lab,
    values=c("#000000", "#990033", "#006699", "#33CC00", "#996633")) +
  ylab("Mean Price") +
  xlab(factor_lab) +
  theme_bw() +
  theme(
    panel.grid.major=element_blank(),
    panel.grid.minor=element_blank(),
    panel.border=element_blank(),
    axis.line=element_line(),
    legend.position = "top",
    legend.box = "vertical",
    legend.text = element_text(size = 5),
    legend.title = element_text(size = 5, face = "bold"),
    legend.key.size = unit(x = 0.4, units = "cm")
  )

}

```


```{r fig.height=4, message=FALSE, warning=FALSE, include=FALSE, out.width='50%'}
# Histograms
# price -> skewed distribution with long right tail
hist_price <- ggplot(data=df, aes(x=price_daily)) +
  geom_histogram(aes(y = (..count..)/sum(..count..)), boundary=0,
                 color = "white", fill = "#440154", alpha = 0.7) +
  coord_cartesian(xlim = c(0, 600)) +
  labs(x = "Price (US dollars)",y = "Percent")+
  scale_y_continuous(labels = scales::percent_format(1)) +
  scale_x_continuous(limits=c(0,600)) + theme_bw() 

# Boxplot for the number of accommodates
accomm <- ggplot(df,aes(factor(accommodates), price_daily, color = "#440154" )) + 
  geom_boxplot(alpha = 0.1, frame = FALSE) + 
  geom_jitter(height = 0, width = 0.1, alpha = 0.2) +
  scale_color_viridis(option = "D", discrete = TRUE)+
  scale_fill_viridis(option = "D", discrete = TRUE) +
  theme_bw() +
  theme(legend.position = "none", panel.border = element_blank(), axis.text=element_text(size=8), plot.title = element_text(size = 12L, face = "bold", hjust = 0.5) ) +
  labs(x = "Number of Accommodates", y = "Price") +
  ggtitle("Price by Number of Accommodates ")


```


```{r message=FALSE, warning=FALSE, include=FALSE}
################################################################################
# PART II - MODELLING
################################################################################


################################################################################
# Setting up models                 
################################################################################

# Basic Variables
basic_lev  <- c("accommodates", "beds", "f_property_type", "n_days_since", "flag_days_since", "f_bathroom")

# Factorized variables
basic_add <- c("f_neighbourhood_cleansed", "f_minimum_nights")
reviews <- c("review_scores_rating", "flag_review_scores_rating", "reviews_per_month", "f_number_of_reviews")
# Higher orders
poly_lev <- c("n_accommodates2", "n_days_since2", "n_days_since3")
# Dummy Variables 
dummies <- grep("^d_.*", names(df), value = TRUE)


################################################################################
# Interactions
################################################################################

#Look up property type interactions
p1 <- price_diff_by_variables2(df, "f_property_type", "AC", "Property Type", "Air Conditioning")
p2 <- price_diff_by_variables2(df, "f_property_type", "tv", "Property Type", "TV")
p3 <- price_diff_by_variables2(df, "f_property_type", "refrigerator", "Property Type", "Refrigerator")
p4 <- price_diff_by_variables2(df, "f_property_type", "wifi", "Property Type", "WIFI")
p5 <-price_diff_by_variables2(df, "f_property_type", "hot_water", "Property Type", "Hot Water")
p6 <- price_diff_by_variables2(df, "f_property_type", "microwave", "Property Type", "Microwave")
p7 <-  price_diff_by_variables2(df, "f_property_type", "heating", "Property Type", "Heating")
p8 <- price_diff_by_variables2(df, "f_property_type", "coffee_maker", "Property Type", "Coffee Maker")
p9 <- price_diff_by_variables2(df, "f_property_type", "accommodates", "Property Type", "Number of Accommodates")
g_interactions1 <- plot_grid(p1, p2, p3, p4, p5, p6, nrow=3, ncol=2) 
g_interactions2 <- plot_grid(p7, p8, p9, nrow=1, ncol=3) 
g_interactions1
g_interactions2


# based on suggested grpaphs
X1 <- c("f_property_type * accommodates")
# Additional dummies based on graphs suggestion
X2  <- c("f_property_type*AC", 
         "f_property_type*refrigerator",
         "f_property_type*tv",
         "f_property_type*wifi",
         "f_property_type*coffee_maker",
         "f_property_type*microwave", 
         "f_property_type*hot_water")

X3  <- c("f_property_type*f_neighbourhood_cleansed", "accommodates*f_neighbourhood_cleansed",
         paste0("(f_property_type) * (",
                paste(dummies, collapse=" + "),")"))

```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Create models in levels models: 1-8
modellev1 <- " ~ accommodates"
modellev2 <- paste0(" ~ ",paste(basic_lev,collapse = " + "))
modellev3 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews),collapse = " + "))
modellev4 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews, poly_lev),collapse = " + "))
modellev5 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews,poly_lev, X1),collapse = " + "))
modellev6 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews,poly_lev, X1, X2),collapse = " + "))
modellev7 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews,poly_lev, X1, X2, dummies),collapse = " + "))
modellev8 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews,poly_lev, X1, X2, dummies, X3),collapse = " + "))

model_table_view <- data.frame(Model = c('M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8'),
                               Predictors = c('Num of accommodates', 
                               'M1 + number of beds + property type + number of days since first review + room type', 
                               'M2 + Num bathrooms + Neighbourhood group + host reponse rate + reviews per month + 
                               reviews scores rating, flag review_scores rating", number_of_reviews',
                               'M3 + squared termof guests + squared and cubic terms of number of days since first review',
                               'M4 + property type and number of guests interaction + property type and room type interaction',
                               'M5 + property type interaction with dummies as air conditioning, TV, wifi, coffee_maker, microwave, hot_water',
                               'M6 + all other amenities',
                               'M7 + all other amenities, Neighbourhoods interacted with property type'))
model_table_view %>%
  kbl(caption = "Copenhagen Airbnb apartment price prediction Models", booktabs = T) %>%
  kable_classic(full_width = T, html_font = "Cambria")

```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Separate hold-out set #
#----------------------------------------
# create a holdout set (20% of observations)
smp_size <- floor(0.2 * nrow(df))
# Set the random number generator: It will make results reproducable
set.seed(12022022)
# A) create ids:
# 1) seq_len: generate regular sequences
# 2) sample: select random rows from a table
holdout_ids <- sample(seq_len(nrow(df)), size = smp_size)
df$holdout <- 0
df$holdout[holdout_ids] <- 1
#Hold-out set Set
data_holdout <- df %>% filter(holdout == 1)
#Working data set
data_work <- df %>% filter(holdout == 0)


```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Utilizing the Working data set:
#   a) estimating measures on the whole working sample (R2,BIC,RMSE)
#   b) Doing K-fold cross validation to get proper Test RMSE

# Create the folds
## K = 5
k_folds=5

# Create the folds
set.seed(20230118)
#Hold-out set Set
data_holdout <- df %>% filter(holdout == 1)
#Working data set
data_work <- df %>% filter(holdout == 0)

folds_i <- sample(rep(1:k_folds, length.out = nrow(data_work)))
for (k in 1:k_folds) {
    test_i <- which(folds_i == k)}
    
data_train <- data_work[-test_i, ]

mse_lev <- function(pred, y) {
  # Mean Squared Error for log models
  (mean((pred - y)^2, na.rm=T))
}
# Create results
model_results_cv <- list()
for (i in (1:8)){
  model_name <-  paste0("modellev",i)
  model_pretty_name <- paste0("(",i,")")
  yvar <- "price_daily"
  xvars <- eval(parse(text = model_name))
  formula <- formula(paste0(yvar,xvars))
  # Initialize values
  rmse_train <- c()
  rmse_test <- c()
  model_work_data <- lm(formula,data = data_work)
  BIC <- BIC(model_work_data)
  nvars <- model_work_data$rank -1
  r2 <- summary(model_work_data)$r.squared
  # Do the k-fold estimation
  for (k in 1:k_folds) {
    test_i <- which(folds_i == k)
    # Train sample: all except test_i
    data_train <- data_work[-test_i, ]
    # Test sample
    data_test <- data_work[test_i, ]
    # Estimation and prediction
    model <- lm(formula,data = data_train)
    prediction_train <- predict(model, newdata = data_train)
    prediction_test <- predict(model, newdata = data_test)
    # Criteria evaluation
    rmse_train[k] <- mse_lev(prediction_train, data_train[,yvar] %>% mean)**(1/2)
    rmse_test[k] <- mse_lev(prediction_test, data_test[,yvar] %>% mean)**(1/2)
  }
  model_results_cv[[model_name]] <- list(yvar=yvar,xvars=xvars,formula=formula,model_work_data=model_work_data,
                                         rmse_train = rmse_train,rmse_test = rmse_test,BIC = BIC,
                                         model_name = model_pretty_name, nvars = nvars, r2 = r2)
}
model <- lm(formula,data = data_train)
prediction_train <- predict(model, newdata = data_train)
prediction_test <- predict(model, newdata = data_test)
#skim(data_train$ln_days_since)
t1 <- imap(model_results_cv,  ~{
  as.data.frame(.x[c("rmse_test", "rmse_train")]) %>%
    dplyr::summarise_all(.funs = mean) %>%
    mutate("model_name" = .y , "model_pretty_name" = .x[["model_name"]] ,
           "nvars" = .x[["nvars"]], "r2" = .x[["r2"]], "BIC" = .x[["BIC"]])
}) %>%
  bind_rows()
t1
column_names <- c("Model", "N predictors", "R-squared", "BIC", "Training RMSE",
                 "Test RMSE")
# R2, BIC on full work data-n.
# In sample rmse: average on training data; avg test : average on test data
OLS_models <- t1 %>%
  select("model_pretty_name", "nvars", "r2" , "BIC", "rmse_train", "rmse_test")
colnames(OLS_models) <- column_names
print(xtable(OLS_models, type = "latex", digits=c(0,0,0,2,0,2,2)), file = paste0(output, "OLS_models.tex"),
      include.rownames=FALSE, booktabs=TRUE, floating = FALSE)
OLS_models
# RMSE training vs test graph
t1_levels <- t1 %>%
  dplyr::select("nvars", "rmse_train", "rmse_test") %>%
  gather(var,value, rmse_train:rmse_test) %>%
  mutate(nvars2=nvars+1) %>%
  mutate(var = factor(var, levels = c("rmse_train", "rmse_test"),
                      labels = c("RMSE Training","RMSE Test")))
model_result_plot_levels <- ggplot(data = t1_levels,
                                   aes(x = factor(nvars2), y = value, color=factor(var), group = var)) +
  geom_line(size=1,show.legend=FALSE, na.rm = TRUE) +
  scale_color_manual(name="",
                     values=c("#fde725","#440154")) +
  geom_dl(aes(label = var),  method = list("last.points", dl.trans(x=x-1), cex=0.4)) +
  theme_bw()
model_result_plot_levels
# Model 7 gives the best result based on the RMSE result

```


```{r message=FALSE, warning=FALSE, include=FALSE}
## K = 5
k_folds=5
# Create the folds
set.seed(20230118)

folds_i <- sample(rep(1:k_folds, length.out = nrow(data_work)))

# Create results
model_names <- c()
model_nvars <- c()
model_bic <- c()
model_r2 <- c()
model_rmse_train <- c()
model_rmse_test <- c()


for (i in (1:8)){
  print(paste0( "Estimating model: " ,i ))
  
  # get model
  model_name <-  paste0("modellev",i)
  model_pretty_name <- paste0("(",i,")")

  # specify formula
  yvar <- "price_daily"
  xvars <- eval(parse(text = model_name))
  formula <- formula(paste0(yvar,xvars))

  # initialize values
  rmse_train <- c()
  rmse_test <- c()
  
  # estimate regression on the whole work data
  model_work_data <- lm(formula,data = data_work)
  BIC <- BIC(model_work_data)
  nvars <- model_work_data$rank -1
  r2 <- summary(model_work_data)$r.squared
  rmse_train = sqrt(sum(model_work_data$residuals^2)/nrow(data_work))
  
  # cross-validation
    cv_i = train(
    formula, data_work, method = 'lm', 
    trControl = trainControl(method = 'cv', number = k_folds)
  )
  
  rmse_test = sqrt(sum(cv_i$resample$RMSE^2)/k_folds)
  
  # gather key metrics
  model_names[i] <- model_pretty_name
  model_nvars[i] <- nvars
  model_bic[i] <- BIC
  model_r2[i] <- r2
  model_rmse_train[i] <- rmse_train
  model_rmse_test[i] <- rmse_test
}

# combine results
cv_result = data.frame(
  model_names, 
  model_nvars, 
  model_bic,
  model_r2, 
  model_rmse_train,
  model_rmse_test)
cv_result
  
colnames(cv_result) <- c('model', 'coefficients', "BIC", "R2", "RMSE_train", "RMSE_test")

colors = c("Training RMSE"="#000000","Test RMSE" = "#990033")

ggplot( data = cv_result, aes( x = factor( coefficients ) , group = 1 ) )+
  geom_line(aes( y = RMSE_train, color = 'Training RMSE'), size = 1 ) +
  geom_point(aes( y = RMSE_train, color = 'Training RMSE'), size = 2 ) + 
  geom_line(aes( y = RMSE_test , color = 'Test RMSE') , size = 1 ) +
  geom_point(aes( y = RMSE_test , color = 'Test RMSE') , size = 2 ) +
  labs(y='RMSE',x='Number of coefficients',color = "", title = "RMSE: Training & Test")+
  scale_color_manual(values = colors) + 
  scale_y_continuous(
    expand = expansion()) +
  theme_bw()+
  theme(legend.position=c(0.5, 0.8))

```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Set lasso tuning parameters:
#----------------------------------------------------
# a) basic setup
train_control <- trainControl( method = "cv", number = k_folds)
# b) tell the actual lambda (penalty parameter) to use for lasso
tune_grid     <- expand.grid("alpha" = c(1), "lambda" = seq(0.05, 1, by = 0.05))
# c) create a formula
# creating two predictors to be used for OLS, LASSO, Random forest, and GBM
predictors_1 <- c(basic_lev, basic_add, reviews, dummies)
predictors_2 <- c(basic_lev,basic_add,reviews,poly_lev, X1, X2, dummies) #Model 7, best model based on CV RMSE

```


```{r message=FALSE, warning=FALSE, include=FALSE}
# OLS BASIC           
#################################
# Using OLS for the Basic variables
set.seed(12345)
system.time({
  ols_model <- train(
    formula(paste0("price_daily ~", paste0(predictors_2, collapse = " + "))),
    data = data_work,
    method = "lm",
    trControl = train_control
  )
})
ols_model_coeffs <-  ols_model$finalModel$coefficients
ols_model_coeffs_df <- data.frame(
  "variable" = names(ols_model_coeffs),
  "ols_coefficient" = ols_model_coeffs
) %>%
  mutate(variable = gsub("`","",variable))

```


```{r message=FALSE, warning=FALSE, include=FALSE}
# LASSO               
# -------------------------------------------------
# setting seed
set.seed(120222)
system.time({
  lasso_model <- caret::train(
    formula(paste0("price_daily ~", paste0(predictors_2, collapse = " + "))),
    data = data_work,
    method = "glmnet",
    tuneGrid =  expand.grid("alpha" = 1, "lambda" = seq(0.01, 0.25, by = 0.01)),
    preProcess = c("center", "scale"),
    trControl = train_control
  )
})
print(lasso_model$bestTune$lambda)
lasso_coeffs <- coef(
  lasso_model$finalModel,
  lasso_model$bestTune$lambda) %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column(var = "variable") %>% 
  rename(coefficient = `s1`)  # the column has a name "1", to be renamed
print(lasso_coeffs)
lasso_coeffs_nz <- lasso_coeffs %>%
  filter(coefficient!=0)
print(nrow(lasso_coeffs_nz))
# Evaluate model. CV error:
lasso_cv_rmse <- lasso_model$results %>%
  filter(lambda == lasso_model$bestTune$lambda) %>%
  dplyr::select(RMSE)
print(lasso_cv_rmse[1, 1])
regression_coeffs <- merge(ols_model_coeffs_df, lasso_coeffs_nz, by = "variable", all=TRUE)
regression_coeffs %>%
  write.csv(file = paste0(output, "regression_coeffs.csv"))

```


```{r message=FALSE, warning=FALSE, include=FALSE}
# CART        
#-------------------------------------------
# setting seed
set.seed(12022022)
system.time({
  cart_model <- train(
    formula(paste0("price_daily ~", paste0(predictors_1, collapse = " + "))),
    data = data_work,
    method = "rpart",
    tuneLength = 10,
    trControl = train_control
  )
})
fancyRpartPlot(cart_model$finalModel, sub = "", palettes = "Purples")

```

```{r message=FALSE, warning=FALSE, include=FALSE}
# RANDOM FOREST     
#-------------------------------------------
# using all variables without their functional forms. Using predictor 1
# setting seed
# set tuning
tune_grid <- expand.grid(
  .mtry = c(8),
  .splitrule = "variance",
  .min.node.size = c(50)
)
# set seed
set.seed(12345)
system.time({
rf_model <- train(
  formula(paste0("price_daily ~", paste0(predictors_1, collapse = " + "))),
  data = data_train,
  method = "ranger",
  trControl = train_control,
  tuneGrid = tune_grid,
  importance = "impurity"
)
})
rf_model
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# GBM              
#----------------------
# Basic GMB model
gbm_grid <-  expand.grid(interaction.depth = c(5, 10), # complexity of the tree
                         n.trees = 250, # Number of trees
                         shrinkage = 0.1, # learning rate: how quickly the algorithm adapts
                         n.minobsinnode = 20 # the minimum number of training set samples in a node to commence splitting
)
set.seed(12345)
system.time({
  gbm_model <- train(formula(paste0("price_daily ~", paste0(predictors_1, collapse = " + "))),
                     data = data_work,
                     method = "gbm",
                     trControl = train_control,
                     verbose = FALSE,
                     tuneGrid = gbm_grid)
})
gbm_model
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# Turning parameter choice 1
result_1 <- matrix(c(
  rf_model$finalModel$mtry,
  rf_model$finalModel$min.node.size
),
nrow=1, ncol=2,
dimnames = list("Model A",
                c("Min vars","Min nodes"))
)
kable(x = result_1, format = "latex", digits = 3) %>%
  cat(.,file= paste0(output,"rf_models_turning_choices.tex"))
```

```{r message=FALSE, warning=FALSE, include=FALSE}
saveRDS(ols_model, paste0(data_out, 'OLS.rds'))
saveRDS(lasso_model, paste0(data_out, 'lasso.rds'))
saveRDS(cart_model, paste0(data_out, 'cart.rds'))
saveRDS(rf_model, paste0(data_out,'random_forest.rds'))
saveRDS(gbm_model, paste0(data_out,'gbm.rds'))
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# FINAL MODELS         
#--------------------------
final_models <-
  list("OLS" = ols_model,
       "LASSO" = lasso_model,
       "CART" = cart_model,
       "Random forest"= rf_model,
       "GBM"  = gbm_model
       )
results <- resamples(final_models) %>% summary()
results
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# Evaluating both data sets R squared
result_3r <- imap(final_models, ~{
  mean(results$values[[paste0(.y,"~Rsquared")]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("CV Rsquared" = ".")
result_3r
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# Evaluating both data sets
result_4 <- imap(final_models, ~{
  mean(results$values[[paste0(.y,"~RMSE")]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("CV RMSE" = ".")
result_4
kable(x = result_4, format = "latex", digits = 3, booktabs=TRUE, linesep = "") %>%
  cat(.,file= paste0(output,"final_models_cv_rmse.tex"))

```

```{r message=FALSE, warning=FALSE, include=FALSE}
# evaluate preferred model on the holdout set -----------------------------
result_5 <- map(final_models, ~{
  RMSE(predict(.x, newdata = data_holdout), data_holdout[["price_daily"]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("Holdout RMSE" = ".")
result_5
kable(x = result_5, format = "latex", digits = 3, booktabs=TRUE, linesep = "") %>%
  cat(.,file= paste0(output,"final_models_houldout_rmse.tex"))
```
```{r message=FALSE, warning=FALSE, include=FALSE}
# Diagnsotics
#-------------------------------------------------
# Variable Importance Plots 
#-------------------------------------------------
# first need a function to calculate grouped varimp
group.importance <- function(rf.obj, groups) {
  var.imp <- as.matrix(sapply(groups, function(g) {
    sum(importance(rf.obj)[g], na.rm = TRUE)
  }))
  colnames(var.imp) <- "MeanDecreaseGini"
  return(var.imp)
}
rf_model_var_imp <- importance(rf_model$finalModel)/1000
rf_model_var_imp_df <-
  data.frame(varname = names(rf_model_var_imp),imp = rf_model_var_imp) %>%
  arrange(desc(imp)) %>%
  mutate(imp_percentage = imp/sum(imp))
```

```{r warning=FALSE, message=FALSE, include=FALSE}
# full varimp plot, top 10 only
rf_model_var_imp_plot_b <- ggplot(
    rf_model_var_imp_df[1:10,], 
    aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color='black', size=3) +
  geom_segment(
    aes(x=varname,xend=varname,y=0,yend=imp_percentage), 
    color='black', size=1) +
  ylab("Importance (Percent)") +
  xlab("Variable Name") +
  labs(title = 'Simple variable importance plots') + 
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bw()


```

```{r message=FALSE, warning=FALSE, include=FALSE}
# 2) varimp plot grouped
#---------------------------------------------
# grouped variable importance - keep binaries created off factors together
varnames <- rf_model$finalModel$xNames
f_neighbourhood_cleansed_varnames <- grep("f_neighbourhood_cleansed",varnames, value = TRUE)
f_property_type_varnames <- grep("f_property_type",varnames, value = TRUE)
groups <- list(f_neighbourhood_cleansed=f_neighbourhood_cleansed_varnames,
               f_bathroom = "f_bathroom",
               n_days_since = "n_days_since",
               accommodates = "n_accommodates",
               beds = "n_beds",
               reviews_per_month="reviews_per_month",
               review_scores_rating="review_scores_rating",
               f_minimum_nights="f_minimum_nights",
               f_number_of_reviews="f_number_of_reviews",
               f_property_type="f_property_type_varnames")
rf_model_var_imp_grouped <- group.importance(rf_model$finalModel, groups)
rf_model_var_imp_grouped_df <- data.frame(varname = rownames(rf_model_var_imp_grouped),
                                            imp = rf_model_var_imp_grouped[,1])  %>%
  mutate(imp_percentage = imp/sum(imp))
rf_model_var_imp_grouped_plot <- ggplot(
    rf_model_var_imp_grouped_df, 
    aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color='black', size=3) +
  geom_segment(
    aes(x=varname,xend=varname,y=0,yend=imp_percentage), 
    color='black', size=1) +
  ylab("Importance (Percent)") +   
  xlab("Variable Name") +
  labs(title = 'Grouped variable importance plots') + 
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bw()

```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Partial Dependence Plots 
# ----------------------------------------------------------------
# Number of accommodates
pdp_n_acc <- pdp::partial(lasso_model, pred.var = "accommodates", pred.grid = distinct_(data_holdout, "accommodates"), train = data_train)
pdp_n_acc_plot <- pdp_n_acc %>%
  autoplot( ) +
  geom_point(color="#440154", size=3) +
  geom_line(color="#440154", size=1) +
  ylab("Predicted price") +
  xlab("Accommodates (persons)") +
  scale_x_continuous(limit=c(1,7), breaks=seq(1,7,1))+
  theme_bw()

```

```{r message=FALSE, warning=FALSE, include=FALSE}
# Subsample performance: RMSE / mean(y) ---------------------------------------
data_holdout_w_prediction <- data_holdout %>%
  mutate(predicted_price = predict(lasso_model, newdata = data_holdout))
######### create nice summary table of heterogeneity
a <- data_holdout_w_prediction %>%
  mutate(is_low_size = ifelse(accommodates <= 3, "small apt", "large apt")) %>%
  group_by(is_low_size) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price_daily),
    mean_price = mean(price_daily),
    rmse_norm = RMSE(predicted_price, price_daily) / mean(price_daily)
  )
b <- data_holdout_w_prediction %>%
  group_by(f_neighbourhood_cleansed) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price_daily),
    mean_price = mean(price_daily),
    rmse_norm = rmse / mean_price
  )
c <- data_holdout_w_prediction %>%
  group_by(f_property_type) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price_daily),
    mean_price = mean(price_daily),
    rmse_norm = rmse / mean_price
  )
d <- data_holdout_w_prediction %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price_daily),
    mean_price = mean(price_daily),
    rmse_norm = RMSE(predicted_price, price_daily) / mean(price_daily)
  )
# Save output
colnames(a) <- c("", "RMSE", "Mean price", "RMSE/price")
colnames(b) <- c("", "RMSE", "Mean price", "RMSE/price")
colnames(c) <- c("", "RMSE", "Mean price", "RMSE/price")
d<- cbind("All", d)
colnames(d) <- c("", "RMSE", "Mean price", "RMSE/price")
line1 <- c("Type", "", "", "")
line2 <- c("Apartment size", "", "", "")
line3 <- c("Neighbourhood", "", "", "")
result_3 <- rbind(line2, a, line1, c, line3, b, d) %>%
  transform(RMSE = as.numeric(RMSE), `Mean price` = as.numeric(`Mean price`),
            `RMSE/price` = as.numeric(`RMSE/price`))
result_3
options(knitr.kable.NA = '')
kable(x = result_3, format = "latex", booktabs=TRUE, linesep = "",digits = c(0,2,1,2), col.names = c("","RMSE","Mean price","RMSE/price")) %>%
  cat(.,file= paste0(output, "performance_across_subsamples.tex"))
options(knitr.kable.NA = NULL)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# FIGURES FOR FITTED VS ACTUAL OUTCOME VARIABLES #
##--------------------------------------------------
Ylev <- data_holdout[["price_daily"]]
# Predicted values
prediction_holdout_pred <- as.data.frame(predict(lasso_model, newdata = data_holdout, interval="predict")) 
predictionlev_holdout <- cbind(data_holdout[,c("price_daily","accommodates")],
                               prediction_holdout_pred)
# Create data frame with the real and predicted values
d <- data.frame(ylev=Ylev, predlev=predictionlev_holdout[,3] )
# Check the differences
d$elev <- d$ylev - d$predlev
# Plot predicted vs price
level_vs_pred <- ggplot(data = d) +
  geom_point(aes(y=ylev, x=predlev), color = "#440154", size = 1,
             shape = 16, alpha = 0.5, show.legend=FALSE, na.rm=TRUE) +
  geom_segment(aes(x = 0, y = 0, xend = 350, yend =350), size=0.8, color="black", linetype=2) +
  labs(y = "Price (US dollars)", x = "Predicted price  (US dollars)") +
  theme_bw() 


```


# Introduction
This report's objective is to give a thorough explanation of the price prediction model. The primary objective of this project is to assist a business in setting a price for brand-new flats that have not yet hit the market. The data is gathered from Inside Airbnb, which can be obtained [here](http://insideairbnb.com/get-the-data), to develop a price prediction model for a business operating small and mid-size apartments hosting two to six guests in Copenhagen, Denmark. Five price prediction models—OLS, Lasso, Cart, Random Forest, and GBM, Gradient Boosting Machine—are produced as a result of data cleaning, munging, and analysis. The project's ultimate goal is to complete a better prediction model as measured by relative RMSE values.

# Data Cleaning 
The original data set consists of a single data table with 75 columns and 13,820 observations. The information relates to one-night rental rates for the period of December 29, 2022. Price per night, per person, expressed in Danish Krone, is the desired variable which is then converted to US dollars. For further cleaning, unnecessary columns were removed, the "amenities" column was transformed into binary variables. factor variables for predictors like neighborhood and property types were also created.
The data was filtered for units that fall between 2 and 6 accommodates. Price per night included extreme values exceeding 1000 USD per night, which comprised fewer than 1% of the observations, therefore price was filtered to less than 600 USD and the observation where price is missing was dropped. As shown below the price distribution is skewed with a long right tail while log price distribution is close to normal. However, prediction is carried out on price per night for model simplicity, also the distribution of number of accommodates for price is also shown in the Figure where as the number of guests increases, prices increases as well.

```{r echo=FALSE, fig.height=3.5, message=FALSE, warning=FALSE, out.width='50%'}
hist_price
accomm
```

# Data Analysis and Feature Engineering 

Feature engineering entails deciding on the type of predictor variables to include as well as the functional forms of predictors and potential interactions. Basic variables include the main predictors such as the number of accommodates, number of beds, property types, number of days since the first review, and its flag variable, and number of bathrooms. Basic addition includes key factorized variables like neighborhoods and minimum nights. Review Variables contain important guest review predictors such as  review score rating and its flag indicating missing values, and factored total number of reviews. Polynomial level is made up of squared terms for number of accommodates as well as squared and cubic terms for days since the first review and dummies include binary values for all amenities.
Three types of interactions were produced: X1 which includes property type multiplied by the number of accommodates. X2 contains property type, air conditioning, refrigerator, WIFI, coffee maker, microwave and hot water dummy variables and X3 includes property types times neighborhood, accommodates times neighborhood groups, and all amenities.

# Modeling
The best model provides the best prediction in the live data.  The original cleaned data is split into two random parts by 20% to 80% ratio in order to avoid over-fitting. The Holdout set includes 20% and the rest 80% is work data set. Then, the work dataset is split into train and test datasets and  5-fold cross validation is run on the train dataset. Then the best model is chosen based on the lowest average of 5 CV RMSE result. Eight basic OLS regression models from simplest to the most complex one were utilized to find the best model for our analysis. 5-fold cross-validation RMSE suggests that Model 7 regression has a better performance and it has the lowest RMSE value of 59.19 USD for the test set. 

## Models

It is critical to run and evaluate various models for a given data set. The following models and algorithms were used to  
- **OLS** and **LASSO** CV-RMSE results using model 7 

- **CART**, **Random Forest**, **GBM** using dummy variables for basic level variables, basic additions, review variables, and amenities.

As a result Random Forest model has a relatively better performance for 5-fold cross validated work set, while LASSO works best for holdout set, as can be seen from the table of models below. The data's 5-fold cross validation RMSE is 58.79 dollars for Random Forest which is the lowest among all models, which is 0.2735 dollars less than the RMSE for LASSO. LASSO outperforms all models in Holdout set with RMSE value of 57.6185 dollars and 5 fold cross validated average RMSE of 59.0655 dollars which is lower than GBM model. It also gives the highest R-squared with value of 33.21% despite penalizing for interaction terms and shrinking some coefficients to zero. Considering external validity and model performance for live data, LASSO is chosen as the best model that has relative better performance in both sets.

```{r echo=FALSE, message=FALSE, warning=FALSE}
final_result4_5 <- cbind(result_4, result_5, result_3r)
final_result4_5 %>% 
  kbl(caption = "Evaluation of Models", digits = 4, align = "lcccr", booktabs=T) %>% 
  kable_minimal(full_width = F, html_font = "Cambria") %>% kable_styling(latex_options = c("HOLD_position", "resizebox=2.5\\textwidth"), font_size = 12, full_width = T) 
```

## Diagnostics

LASSO is an algorithm that fits a model by shrinking the coefficients and even shrinks some of them to zero is chosen as the best model. Diagnostic tools, on the other hand, can be used to uncover information about the patterns of association that drive prediction. Some examples are as follows:
**Variable Importance Plot** depicts the average importance of fit when an x variable or set of x variables is used. Plot of variable importance for The top ten most important variables show that number of accommodates and beds, Indre By neighborhood, review variables are the most important. The importance of grouped variables reveals that neighborhoods, reviews, and days since first review are important.

```{r echo=FALSE, message=FALSE, warning=FALSE, out.width='50%', fig.height=3.5}
# ploting the variable importance plot
rf_model_var_imp_plot_b
rf_model_var_imp_grouped_plot
```

**Partial Dependence Plot** depicts how average y varies for different x values in relation to all other predictor variables. The partial dependence plot is based on the holdout set's predictors. The partial dependence plot for the number of accommodates and the price shows that the price rises as the number of accommodates increases.
**Actual vs Predicted Price** Another post-prediction diagnostic is a comparison of predicted and actual prices. The graph below shows that prediction performs better for lower prices than for higher prices. However, for prices above 200 dollars, the model seems to not fit well.

```{r echo=FALSE, message=FALSE, warning=FALSE, out.width='50%', fig.height=4}
pdp_n_acc_plot
level_vs_pred
```

## Conclusion
The purpose of this report was to develop a more accurate model for predicting Airbnb prices in Copenhagen for small to mid-size apartments. Five models were depicted in order to compare and contrast their performance. The basic LASSO model with lambda value of 0.01 , which highlights meaningful characteristics about the nature of Airbnb apartments in Copenhagen was the best model with a 59.065 dollars RMSE, while it performed best in the holdout set with a 57.618 dollars RMSE. While OLS came in second place with 57.64 dollars RMSE for holdout set. In this study, simple models such as LASSO and OLS outperformed complicated models such as GBM and CART. Therefore, LASSO is chosen as the best model; however, results can be different depending on the dataset. The neighbouhood, days since first review, property type, number of bathrooms, the number of accommodations, review scores rating and reviews per month are key price drivers based on post prediction diagnostics. 


